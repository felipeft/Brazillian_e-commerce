{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a319011b",
   "metadata": {},
   "source": [
    "Criação de um modelo supervisionado de classificação para prever se um pedido será entregue no prazo\n",
    "para isso, precisa ser feito a classificação de pedidos entregues no prazo vs atrasados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde3cf0",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4799031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas principais para análise e modelagem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de99dc",
   "metadata": {},
   "source": [
    "## Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4891889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>...</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "      <th>product_category_name_english</th>\n",
       "      <th>delivery_time_days</th>\n",
       "      <th>estimated_time_days</th>\n",
       "      <th>delay</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "      <td>housewares</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>38.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "      <td>housewares</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>38.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>7c396fd4830fd04220f754e42b4e5bff</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9350.0</td>\n",
       "      <td>maua</td>\n",
       "      <td>SP</td>\n",
       "      <td>housewares</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>38.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>af07308b275d755c9edb36a90c618231</td>\n",
       "      <td>47813</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31570.0</td>\n",
       "      <td>belo horizonte</td>\n",
       "      <td>SP</td>\n",
       "      <td>perfumery</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>141.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>3a653a41f6f9fc3d2a113cf8398680e8</td>\n",
       "      <td>75265</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14840.0</td>\n",
       "      <td>guariba</td>\n",
       "      <td>SP</td>\n",
       "      <td>auto</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>179.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "2  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "3  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "4  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "\n",
       "  order_status order_purchase_timestamp   order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "1    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "2    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
       "3    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
       "4    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "2          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "3          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "4          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "\n",
       "  order_estimated_delivery_date                customer_unique_id  \\\n",
       "0                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
       "1                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
       "2                    2017-10-18  7c396fd4830fd04220f754e42b4e5bff   \n",
       "3                    2018-08-13  af07308b275d755c9edb36a90c618231   \n",
       "4                    2018-09-04  3a653a41f6f9fc3d2a113cf8398680e8   \n",
       "\n",
       "   customer_zip_code_prefix  ... product_height_cm product_width_cm  \\\n",
       "0                      3149  ...               8.0             13.0   \n",
       "1                      3149  ...               8.0             13.0   \n",
       "2                      3149  ...               8.0             13.0   \n",
       "3                     47813  ...              13.0             19.0   \n",
       "4                     75265  ...              19.0             21.0   \n",
       "\n",
       "   seller_zip_code_prefix     seller_city seller_state  \\\n",
       "0                  9350.0            maua           SP   \n",
       "1                  9350.0            maua           SP   \n",
       "2                  9350.0            maua           SP   \n",
       "3                 31570.0  belo horizonte           SP   \n",
       "4                 14840.0         guariba           SP   \n",
       "\n",
       "  product_category_name_english  delivery_time_days  estimated_time_days  \\\n",
       "0                    housewares                 8.0                   15   \n",
       "1                    housewares                 8.0                   15   \n",
       "2                    housewares                 8.0                   15   \n",
       "3                     perfumery                13.0                   19   \n",
       "4                          auto                 9.0                   26   \n",
       "\n",
       "   delay total_price  \n",
       "0      0       38.71  \n",
       "1      0       38.71  \n",
       "2      0       38.71  \n",
       "3      0      141.46  \n",
       "4      0      179.12  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar a tabela consolidada criada no ETL\n",
    "df = pd.read_parquet(\"/home/felipe/Desktop/Projetos Free ml/Brazilian_E-Commerce/data/processed/orders_table.parquet\")\n",
    "\n",
    "# Visualizar primeiras linhas\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5911fb6",
   "metadata": {},
   "source": [
    "## Seleção de features e target\n",
    "\n",
    "Não selecionamos todas as features por enquanto, mas podemos ir adicionando mais\n",
    "essas são as mais relevantes até então"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d065a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados de treino: (91519, 10)\n",
      "Shape dos dados de teste: (22880, 10)\n"
     ]
    }
   ],
   "source": [
    "def create_features_and_target(df):\n",
    "    \"\"\"\n",
    "    Cria a variável alvo e seleciona features mais relevantes.\n",
    "    \"\"\"\n",
    "    # Converter as colunas de data para o tipo datetime\n",
    "    df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "    df['order_delivered_customer_date'] = pd.to_datetime(df['order_delivered_customer_date'])\n",
    "    df['order_estimated_delivery_date'] = pd.to_datetime(df['order_estimated_delivery_date'])\n",
    "\n",
    "    # Calcular a diferença de dias entre a entrega real e a estimada (nosso target)\n",
    "    df['delivery_diff'] = (df['order_delivered_customer_date'] - df['order_estimated_delivery_date']).dt.days\n",
    "    df['is_late'] = (df['delivery_diff'] > 0).astype(int)\n",
    "\n",
    "    # Calcular o tempo de aprovação do pagamento em dias\n",
    "    df['payment_approval_time_days'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / (60*60*24)\n",
    "    # Calcular o tempo de entrega para a transportadora em dias\n",
    "    df['carrier_delivery_time_days'] = (df['order_delivered_carrier_date'] - df['order_approved_at']).dt.total_seconds() / (60*60*24)\n",
    "\n",
    "    # Features que fazem mais sentido para a previsão\n",
    "    selected_features = [\n",
    "        'customer_state',               # Estado do cliente pode influenciar o tempo de entrega\n",
    "        'product_category_name_english',  # Categoria do produto pode ter diferentes logísticas\n",
    "        'price',                        # Preço pode estar relacionado à urgência ou tipo de produto\n",
    "        'freight_value',                # O valor do frete está diretamente relacionado ao serviço de entrega\n",
    "        'payment_installments',         # Número de parcelas pode ser um proxy para o valor do produto\n",
    "        'review_score',                 # Score de avaliação do cliente pode ter relação com o atraso\n",
    "        'seller_state',                 # A localização do vendedor afeta a distância do frete\n",
    "        'product_weight_g',             # O peso do produto afeta o frete\n",
    "        'payment_approval_time_days',   # Tempo de aprovação afeta o início da entrega\n",
    "        'carrier_delivery_time_days'    # Tempo de envio para a transportadora\n",
    "    ]\n",
    "\n",
    "    target = 'is_late'\n",
    "    \n",
    "    # Remover linhas com valores nulos nas features selecionadas\n",
    "    df_cleaned = df.dropna(subset=selected_features + [target])\n",
    "\n",
    "    return df_cleaned[selected_features + [target]]\n",
    "\n",
    "# Executar a função e separar os dados\n",
    "df_processed = create_features_and_target(df)\n",
    "X = df_processed.drop('is_late', axis=1)\n",
    "y = df_processed['is_late']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape dos dados de treino:\", X_train.shape)\n",
    "print(\"Shape dos dados de teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e197a",
   "metadata": {},
   "source": [
    "## Divisão em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbfbc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho treino: (91519, 10)\n",
      "Tamanho teste: (22880, 10)\n"
     ]
    }
   ],
   "source": [
    "# Dividir os dados em treino e teste (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Tamanho treino:\", X_train.shape)\n",
    "print(\"Tamanho teste:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784c0b8",
   "metadata": {},
   "source": [
    "## Variaveis categóricas e numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f5df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 114399 entries, 0 to 119142\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   customer_state                 114399 non-null  object \n",
      " 1   product_category_name_english  114399 non-null  object \n",
      " 2   price                          114399 non-null  float64\n",
      " 3   freight_value                  114399 non-null  float64\n",
      " 4   payment_installments           114399 non-null  float64\n",
      " 5   review_score                   114399 non-null  float64\n",
      " 6   seller_state                   114399 non-null  object \n",
      " 7   product_weight_g               114399 non-null  float64\n",
      " 8   payment_approval_time_days     114399 non-null  float64\n",
      " 9   carrier_delivery_time_days     114399 non-null  float64\n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 9.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd24e9",
   "metadata": {},
   "source": [
    "verificando se há valores faltantes para não atraplhar a normalização e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01da359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_state                   0\n",
       "product_category_name_english    0\n",
       "price                            0\n",
       "freight_value                    0\n",
       "payment_installments             0\n",
       "review_score                     0\n",
       "seller_state                     0\n",
       "product_weight_g                 0\n",
       "payment_approval_time_days       0\n",
       "carrier_delivery_time_days       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2085b",
   "metadata": {},
   "source": [
    "Pré processamento com pipeline e normalização "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7a56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as features numéricas e categóricas\n",
    "numeric_features = ['price', 'freight_value', 'payment_installments', 'review_score', 'product_weight_g', 'payment_approval_time_days', 'carrier_delivery_time_days']\n",
    "categorical_features = ['customer_state', 'product_category_name_english', 'seller_state']\n",
    "\n",
    "# Criar o pré-processador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c7de7",
   "metadata": {},
   "source": [
    "## Modelo baseline (Regressão Logística)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2af0050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Regressão Logística ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     21431\n",
      "           1       0.67      0.12      0.20      1449\n",
      "\n",
      "    accuracy                           0.94     22880\n",
      "   macro avg       0.81      0.56      0.58     22880\n",
      "weighted avg       0.93      0.94      0.92     22880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo de Regressão Logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"== Regressão Logística ==\")\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526659b",
   "metadata": {},
   "source": [
    "## Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e379709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Árvore de Decisão ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     21431\n",
      "           1       0.41      0.41      0.41      1449\n",
      "\n",
      "    accuracy                           0.92     22880\n",
      "   macro avg       0.68      0.68      0.68     22880\n",
      "weighted avg       0.93      0.92      0.92     22880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo de Árvore de Decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"== Árvore de Decisão ==\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504524c3",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a96d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Random Forest ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     21431\n",
      "           1       0.86      0.28      0.42      1449\n",
      "\n",
      "    accuracy                           0.95     22880\n",
      "   macro avg       0.91      0.64      0.70     22880\n",
      "weighted avg       0.95      0.95      0.94     22880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo de Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"== Random Forest ==\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49f7a4",
   "metadata": {},
   "source": [
    "## Comparação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c77611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela de Comparação de Modelos:\n",
      "                     Accuracy  Precision    Recall  F1-Score\n",
      "Logistic Regression  0.940472   0.673307  0.116632  0.198824\n",
      "Decision Tree        0.924956   0.407713  0.408558  0.408135\n",
      "Random Forest        0.951573   0.857442  0.282264  0.424714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular as métricas para cada modelo\n",
    "log_reg_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_log_reg),\n",
    "    'Precision': precision_score(y_test, y_pred_log_reg, zero_division=0),\n",
    "    'Recall': recall_score(y_test, y_pred_log_reg, zero_division=0),\n",
    "    'F1-Score': f1_score(y_test, y_pred_log_reg, zero_division=0)\n",
    "}\n",
    "\n",
    "dt_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_dt),\n",
    "    'Precision': precision_score(y_test, y_pred_dt, zero_division=0),\n",
    "    'Recall': recall_score(y_test, y_pred_dt, zero_division=0),\n",
    "    'F1-Score': f1_score(y_test, y_pred_dt, zero_division=0)\n",
    "}\n",
    "\n",
    "rf_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Precision': precision_score(y_test, y_pred_rf, zero_division=0),\n",
    "    'Recall': recall_score(y_test, y_pred_rf, zero_division=0),\n",
    "    'F1-Score': f1_score(y_test, y_pred_rf, zero_division=0)\n",
    "}\n",
    "\n",
    "# Criar um DataFrame para a comparação\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Logistic Regression': log_reg_metrics,\n",
    "    'Decision Tree': dt_metrics,\n",
    "    'Random Forest': rf_metrics\n",
    "})\n",
    "\n",
    "print(\"Tabela de Comparação de Modelos:\")\n",
    "print(comparison_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cf7f7",
   "metadata": {},
   "source": [
    "## interpretação\n",
    "\n",
    "- Primeiramente, esse dataset é desbalanceado, pois temos mais valores de \"chegou no prazo\" ou '0' do que \"atrasado\" ou '1'.\n",
    "\n",
    "- Então fica facil para o modelo prever as entregas que chegarão no prazo haja visto que isso é maioria\n",
    "\n",
    "- portanto, para cada modelo, valores acuracia se mostram bem excelentes (0.92 -> 0.95), mas isso não quer dizer muita coisa pois existe esse desbalanceamento.\n",
    "\n",
    "- A precisão por outro lado, se mostrou melhor no random forest, depois regressao logista e por fim arvore de decisão (pessima)\n",
    "\n",
    "- Já em relação ao recall (das realmente atrasadas quantas o modelo encontrou) não tivemos resultados tão expresivos para cada modelo sendo a regressao logistica a pior (12%), depois random forest e a melhor sendo a arvore de decisão\n",
    "\n",
    "- O f1-score que seria a relação entre a precisao (quantas o modelo disse que estão atrasadas realmente estao) e o recall (das que realmente sao atrasadas quantas o modelo acertou) se mostrou quase igual entre a arvore de decisao e o random forest sendo o ultimo melhor (0.4081 < 0.4247)\n",
    "\n",
    "- Ao todo os modelos avaliaram 22.880 casos como indicado pelo support. 21.431 sem atraso vs 1449 com atraso confirmando aquilo que foi falado antes sobre o desbalanceamento do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ae65b",
   "metadata": {},
   "source": [
    "Aplicando o Synthetic Minority Over-sampling Technique ou SMOTE para corrigir esse desbalanceamento\n",
    "\n",
    "O SMOTE não apaga os dados da classe majoritária, mas sim cria dados sintéticos da classe minoritária (os pedidos atrasados) para equilibrar o conjunto de dados. Isso força o modelo a aprender o \"atraso\" em vez de simplesmente ignorá-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4d08c",
   "metadata": {},
   "source": [
    "## Balanceamento dos dados com SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a02a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de classes antes do SMOTE: Counter({0: 85722, 1: 5797})\n",
      "Contagem de classes após o SMOTE: Counter({0: 85722, 1: 85722})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Separar as features numéricas e categóricas\n",
    "X_num = X_train[numeric_features]\n",
    "X_cat = X_train[categorical_features]\n",
    "\n",
    "# Aplicar o OneHotEncoder para as features categóricas para o SMOTE\n",
    "preprocessor_for_smote = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "X_cat_encoded = preprocessor_for_smote.fit_transform(X_train)\n",
    "\n",
    "# Combinar dados codificados e numéricos\n",
    "X_train_processed = np.hstack([X_cat_encoded.toarray(), X_num])\n",
    "\n",
    "# Contar o número de classes antes do SMOTE\n",
    "print(\"Contagem de classes antes do SMOTE:\", Counter(y_train))\n",
    "\n",
    "# Aplicar o SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "print(\"Contagem de classes após o SMOTE:\", Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bd6e1",
   "metadata": {},
   "source": [
    "## Treinando os modelos novamente com os dados balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e244e609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/felipe/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# O pipeline agora não precisa do preprocessor, pois os dados já foram transformados para o SMOTE\n",
    "# No entanto, a padronização das features numéricas ainda é necessária. \n",
    "# Reajustando a lógica de treino para o notebook.\n",
    "\n",
    "# Treinar Regressão Logística\n",
    "# É necessário aplicar o StandardScaler nos dados numéricos novamente, pois o SMOTE não o faz.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled[:, -len(numeric_features):]) # Padroniza os dados numéricos após o SMOTE\n",
    "X_train_final = np.hstack([X_train_resampled[:, :-len(numeric_features)], X_train_scaled])\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "X_test_final = np.hstack([preprocessor_for_smote.transform(X_test).toarray(), X_test_scaled])\n",
    "\n",
    "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg_model.fit(X_train_final, y_train_resampled)\n",
    "y_pred_log_reg_smote = log_reg_model.predict(X_test_final)\n",
    "\n",
    "# Treinar Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_final, y_train_resampled)\n",
    "y_pred_rf_smote = rf_model.predict(X_test_final)\n",
    "\n",
    "# O `ColumnTransformer` é melhor usado dentro do `Pipeline`, então vamos seguir a melhor prática para o próximo passo.\n",
    "# Por enquanto, esta forma manual demonstra o impacto do SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591e211",
   "metadata": {},
   "source": [
    "## Comparando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2331da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Regressão Logística (com SMOTE) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89     21431\n",
      "           1       0.21      0.74      0.33      1449\n",
      "\n",
      "    accuracy                           0.81     22880\n",
      "   macro avg       0.60      0.78      0.61     22880\n",
      "weighted avg       0.93      0.81      0.85     22880\n",
      "\n",
      "\n",
      "== Random Forest (com SMOTE) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     21431\n",
      "           1       0.69      0.39      0.50      1449\n",
      "\n",
      "    accuracy                           0.95     22880\n",
      "   macro avg       0.83      0.69      0.74     22880\n",
      "weighted avg       0.94      0.95      0.94     22880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"== Regressão Logística (com SMOTE) ==\")\n",
    "print(classification_report(y_test, y_pred_log_reg_smote))\n",
    "\n",
    "print(\"\\n== Random Forest (com SMOTE) ==\")\n",
    "print(classification_report(y_test, y_pred_rf_smote))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
